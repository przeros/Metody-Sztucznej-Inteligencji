ylab = "y",
main = "Regresja modeli. Dane treningowe.")
model1 = lm(formula = y ~ x)
points(
x = x,
y = predict(model1, data.frame(x)),
type = "l",
col = "green"
)
model2 = lm(formula = y ~ I(x^3) + I(x^2) + x)
points(
x = x,
y = predict(model2, data.frame(x)),
type = "l",
col = "red"
)
model3 = lm(formula = y ~ I(x^5) + I(x^4) + I(x^3) + I(x^2) + x)
points(
x = x,
y = predict(model3, data.frame(x)),
type = "l",
col = "blue"
)
model4 = lm(formula = y ~ log(x))
points(
x = x,
y = predict(model4, data.frame(x)),
type = "l",
col = "purple"
)
model5 = lm(formula = y ~ tan(x))
points(
x = x,
y = predict(model5, data.frame(x)),
type = "l",
col = "yellow"
)
error = y - predict(model1, data.frame(x))
modelError1 = mean(error ^ 2) #błąd średniokwadratowy
error2 = y - predict(model2, data.frame(x))
modelError2 = mean(error2 ^ 2) #błąd średniokwadratowy
error3 = y - predict(model3, data.frame(x))
modelError3 = mean(error3 ^ 2) #błąd średniokwadratowy
error4 = y - predict(model4, data.frame(x))
modelError4 = mean(error4 ^ 2) #błąd średniokwadratowy
error5 = y - predict(model5, data.frame(x))
modelError5 = mean(error5 ^ 2) #błąd średniokwadratowy
writeLines(sprintf(
"Kolejne modele uzyskiwały następujące błędy treningowe:
liniowy: %.2f
wielomianowy 3 stopnia: %.2f
wielomianowy 5 stopnia: %.2f
logarytmiczny: %.2f
tangens: %.2f",
modelError1,
modelError2,
modelError3,
modelError4,
modelError5
))
set.seed(0) #poniższe generowanie losowe da zawsze ten sam wynik
noisetest = rnorm(n = length(yideal),
mean = 0,
sd = 0.5)
plot(noisetest, main = "Szum")
ytest = yideal + noisetest
plot(x, ytest, main = "Zaszumione pomiary y testowego")
error = ytest - predict(model1, data.frame(x))
modelError1 = mean(error ^ 2) #błąd średniokwadratowy
error2 = ytest - predict(model2, data.frame(x))
modelError2 = mean(error2 ^ 2) #błąd średniokwadratowy
error3 = ytest - predict(model3, data.frame(x))
modelError3 = mean(error3 ^ 2) #błąd średniokwadratowy
error4 = ytest - predict(model4, data.frame(x))
modelError4 = mean(error4 ^ 2) #błąd średniokwadratowy
error5 = ytest - predict(model5, data.frame(x))
modelError5 = mean(error5 ^ 2) #błąd średniokwadratowy
plot(x,
ytest,
xlab = "x",
ylab = "ytest",
main = "Regresja modeli. Dane testowe")
points(
x = x,
y = predict(model1, data.frame(x)),
type = "l",
col = "green"
)
points(
x = x,
y = predict(model2, data.frame(x)),
type = "l",
col = "red"
)
points(
x = x,
y = predict(model3, data.frame(x)),
type = "l",
col = "blue"
)
points(
x = x,
y = predict(model4, data.frame(x)),
type = "l",
col = "purple"
)
points(
x = x,
y = predict(model5, data.frame(x)),
type = "l",
col = "yellow"
)
writeLines(sprintf(
"Kolejne modele uzyskiwały następujące błędy testowe:
liniowy: %.2f
wielomianowy 3 stopnia: %.2f
wielomianowy 5 stopnia: %.2f
logarytmiczny: %.2f
tangens: %.2f",
modelError1,
modelError2,
modelError3,
modelError4,
modelError5
))
#wyznaczone statystyki wartości, do użycia w modelu gęstości prawdopodobieństwa
mr = mean(r)
sdr = sd(r)
mm = mean(m)
sdm = sd(m)
sprintf(
"Średnia i odchylenie dla klasy %s równe są: mean %0.4f sd %0.4f",
c("R", "M"),
c(mr, mm),
c(sdr, sdm)
)
error = y - predict(model1, data.frame(x))
modelError1 = mean(error ^ 2) #błąd średniokwadratowy
error2 = y - predict(model2, data.frame(x))
modelError2 = mean(error2 ^ 2) #błąd średniokwadratowy
error3 = y - predict(model3, data.frame(x))
modelError3 = mean(error3 ^ 2) #błąd średniokwadratowy
error4 = y - predict(model4, data.frame(x))
modelError4 = mean(error4 ^ 2) #błąd średniokwadratowy
error5 = y - predict(model5, data.frame(x))
modelError5 = mean(error5 ^ 2) #błąd średniokwadratowy
writeLines(sprintf(
"Kolejne modele uzyskiwały następujące błędy treningowe:
liniowy: %.2f
wielomianowy 3 stopnia: %.2f
wielomianowy 5 stopnia: %.2f
logarytmiczny: %.2f
tangens: %.2f",
modelError1,
modelError2,
modelError3,
modelError4,
modelError5
))
set.seed(0) #poniższe generowanie losowe da zawsze ten sam wynik
noisetest = rnorm(n = length(yideal),
mean = 0,
sd = 0.5)
plot(noisetest, main = "Szum")
ytest = yideal + noisetest
plot(x, ytest, main = "Zaszumione pomiary y testowego")
error = ytest - predict(model1, data.frame(x))
modelError1 = mean(error ^ 2) #błąd średniokwadratowy
error2 = ytest - predict(model2, data.frame(x))
modelError2 = mean(error2 ^ 2) #błąd średniokwadratowy
error3 = ytest - predict(model3, data.frame(x))
modelError3 = mean(error3 ^ 2) #błąd średniokwadratowy
error4 = ytest - predict(model4, data.frame(x))
modelError4 = mean(error4 ^ 2) #błąd średniokwadratowy
error5 = ytest - predict(model5, data.frame(x))
modelError5 = mean(error5 ^ 2) #błąd średniokwadratowy
plot(x,
ytest,
xlab = "x",
ylab = "ytest",
main = "Regresja modeli. Dane testowe")
points(
x = x,
y = predict(model1, data.frame(x)),
type = "l",
col = "green"
)
points(
x = x,
y = predict(model2, data.frame(x)),
type = "l",
col = "red"
)
points(
x = x,
y = predict(model3, data.frame(x)),
type = "l",
col = "blue"
)
points(
x = x,
y = predict(model4, data.frame(x)),
type = "l",
col = "purple"
)
points(
x = x,
y = predict(model5, data.frame(x)),
type = "l",
col = "yellow"
)
writeLines(sprintf(
"Kolejne modele uzyskiwały następujące błędy testowe:
liniowy: %.2f
wielomianowy 3 stopnia: %.2f
wielomianowy 5 stopnia: %.2f
logarytmiczny: %.2f
tangens: %.2f",
modelError1,
modelError2,
modelError3,
modelError4,
modelError5
))
plot(x, yideal, main = "Niezaszumione pomiary y testowego")
error = yideal - predict(model1, data.frame(x))
modelError1 = mean(error ^ 2) #błąd średniokwadratowy
error2 = (yideal - predict(model2, data.frame(x)))
modelError2 = mean(error2 ^ 2) #błąd średniokwadratowy
error3 = (yideal - predict(model3, data.frame(x)))
modelError3 = mean(error3 ^ 2) #błąd średniokwadratowy
error4 = (yideal - predict(model4, data.frame(x)))
modelError4 = mean(error4 ^ 2) #błąd średniokwadratowy
error5 = (yideal - predict(model5, data.frame(x)))
modelError5 = mean(error5 ^ 2) #błąd średniokwadratowy
plot(x,
yideal,
xlab = "x",
ylab = "yideal",
main = "Regresja modeli. Dane niezaszumione")
points(
x = x,
y = predict(model1, data.frame(x)),
type = "l",
col = "green"
)
points(
x = x,
y = predict(model2, data.frame(x)),
type = "l",
col = "red"
)
points(
x = x,
y = predict(model3, data.frame(x)),
type = "l",
col = "blue"
)
points(
x = x,
y = predict(model4, data.frame(x)),
type = "l",
col = "purple"
)
points(
x = x,
y = predict(model5, data.frame(x)),
type = "l",
col = "yellow"
)
writeLines(sprintf(
"Kolejne modele uzyskiwały następujące błędy testowe:
liniowy: %.2f
wielomianowy 3 stopnia: %.2f
wielomianowy 5 stopnia: %.2f
logarytmiczny: %.2f
tangens: %.2f",
modelError1,
modelError2,
modelError3,
modelError4,
modelError5
))
library(mlbench)
data(Sonar) #wczytanie zbioru danych do środowiska. Dokumentację wywołać można poleceniem ?Sonar
summary(Sonar) #proste podsumowanie danych, przedziały kwartylowe
plot(Sonar$Class, Sonar$V9)
plot(Sonar$V9, Sonar$Class)
r = Sonar$V9[Sonar$Class == "R"]
m = Sonar$V9[Sonar$Class == "M"]
hist(r)
hist(m)
#wyznaczone statystyki wartości, do użycia w modelu gęstości prawdopodobieństwa
mr = mean(r)
sdr = sd(r)
mm = mean(m)
sdm = sd(m)
sprintf(
"Średnia i odchylenie dla klasy %s równe są: mean %0.4f sd %0.4f",
c("R", "M"),
c(mr, mm),
c(sdr, sdm)
)
x = seq(0, 0.8, length = 200)
mteoret = dnorm(x, mean = mm, sd = sdm)
rteoret = dnorm(x, mean = mr, sd = sdr)
plot(
x,
rteoret,
ylab = "Funkcja gęstości prawdopodobieństwa dla x",
xlab = "Wartość cechy V9",
main = "Gęstość prawdopodobieństwa dla klasy R-czarne, M-czerwone",
type = "l",
col = "black"
)
points(x, mteoret, type = "l", col = "red")
plot(
x,
rteoret,
ylab = "Prawdopodobieństwo",
xlab = "Wartość cechy V9",
main = "Prawdopodobieństwo dla klasy R-czarne, M-czerwone",
type = "l",
col = "black"
)
points(x, mteoret, type = "l", col = "red")
prog = 0.14
points(c(prog, prog), c(0, 1), col = "black", type = "l")
points(x[x > prog], rteoret[x > prog], pch = 4, col = "black")
points(x[x <= prog], mteoret[x <= prog], pch = 4, col = "red")
#(linia pionowa - próg decyzyjny, krzyżyki - błędy)
plot(
x,
rteoret,
ylab = "Prawdopodobieństwo",
xlab = "Wartość cechy V9",
main = "Prawdopodobieństwo dla klasy R-czarne, M-czerwone",
type = "l",
col = "black"
)
points(x, mteoret, type = "l", col = "red")
prog = 0.14
points(c(prog, prog), c(0, 1), col = "black", type = "l")
points(x[x > prog], rteoret[x > prog], pch = 4, col = "black")
points(x[x <= prog], mteoret[x <= prog], pch = 4, col = "red")
#(linia pionowa - próg decyzyjny, krzyżyki - błędy)
x = seq(0, 0.8, length = 200)
mteoret = dnorm(x, mean = mm, sd = sdm)
rteoret = dnorm(x, mean = mr, sd = sdr)
plot(
x,
rteoret,
ylab = "Funkcja gęstości prawdopodobieństwa dla x",
xlab = "Wartość cechy V9",
main = "Gęstość prawdopodobieństwa dla klasy R-czarne, M-czerwone",
type = "l",
col = "black"
)
points(x, mteoret, type = "l", col = "red")
plot(
x,
rteoret,
ylab = "Prawdopodobieństwo",
xlab = "Wartość cechy V9",
main = "Prawdopodobieństwo dla klasy R-czarne, M-czerwone",
type = "l",
col = "black"
)
points(x, mteoret, type = "l", col = "red")
prog = 0.14
points(c(prog, prog), c(0, 1), col = "black", type = "l")
points(x[x > prog], rteoret[x > prog], pch = 4, col = "black")
points(x[x <= prog], mteoret[x <= prog], pch = 4, col = "red")
#(linia pionowa - próg decyzyjny, krzyżyki - błędy)
plot(
x,
rteoret,
ylab = "Prawdopodobieństwo",
xlab = "Wartość cechy V9",
main = "Prawdopodobieństwo dla klasy R-czarne, M-czerwone",
type = "l",
col = "black"
)
points(x, mteoret, type = "l", col = "red")
prog = 0.14
points(c(prog, prog), c(0, 1), col = "black", type = "l")
points(x[x > prog], rteoret[x > prog], pch = 4, col = "black")
points(x[x <= prog], mteoret[x <= prog], pch = 4, col = "red")
#(linia pionowa - próg decyzyjny, krzyżyki - błędy)
plot(
x,
rteoret,
ylab = "Prawdopodobieństwo",
xlab = "Wartość cechy V9",
main = "Prawdopodobieństwo dla klasy R-czarne, M-czerwone",
type = "l",
col = "black"
)
points(x, mteoret, type = "l", col = "red")
prog = 0.14
points(c(prog, prog), c(0, max(rteoret)), col = "black", type = "l")
points(x[x > prog], rteoret[x > prog], pch = 4, col = "black")
points(x[x <= prog], mteoret[x <= prog], pch = 4, col = "red")
#(linia pionowa - próg decyzyjny, krzyżyki - błędy)
plot(
x,
rteoret,
ylab = "Prawdopodobieństwo",
xlab = "Wartość cechy V9",
main = "Prawdopodobieństwo dla klasy R-czarne, M-czerwone",
type = "l",
col = "black"
)
points(x, mteoret, type = "l", col = "red")
prog = 0.14
points(c(prog, prog), c(0, max(rteoret, mteoret)), col = "black", type = "l")
points(x[x > prog], rteoret[x > prog], pch = 4, col = "black")
points(x[x <= prog], mteoret[x <= prog], pch = 4, col = "red")
#(linia pionowa - próg decyzyjny, krzyżyki - błędy)
prog = 0.14
liczbaR = sum(Sonar$Class == "R")
liczbaM = sum(Sonar$Class == "M")
R.T = sum(Sonar$V9[Sonar$Class == "R"] < prog)
R.TPR = R.T / liczbaR #true positive rate
M.T = sum(Sonar$V9[Sonar$Class == "M"] >= prog)
M.TPR = M.T / liczbaM #true positive rate
sprintf(
"Dla progu decyzyjnego V9 = %0.2f true positive rate dla klasy %s wynosi %0.2f",
c(prog),
c("R", "M"),
c(R.TPR, M.TPR)
)
R.F = sum(Sonar$V9[Sonar$Class == "R"] >= prog) #czarne krzyżyki
R.FNR = R.F / liczbaR #false negative rate
M.F = sum(Sonar$V9[Sonar$Class == "M"] < prog) #czerwone krzyżyki
M.FNR = M.F / liczbaM #false negative rate
sprintf(
"Dla progu decyzyjnego V9 = %0.2f false negative rate dla klasy %s wynosi %0.2f",
c(prog),
c("R", "M"),
c(R.FNR, M.FNR)
)
R.FPR = M.F / liczbaM #false positive rate
M.FPR = R.F / liczbaR #false positive rate
sprintf(
"Dla progu decyzyjnego V9 = %0.2f false positive rate dla klasy %s wynosi %0.2f",
c(prog),
c("R", "M"),
c(R.FPR, M.FPR)
)
R.TNR = M.T / liczbaM #true negative rate
M.TNR = R.T / liczbaR #true negative rate
sprintf(
"Dla progu decyzyjnego V9 = %0.2f true negative rate dla klasy %s wynosi %0.2f",
c(prog),
c("R", "M"),
c(R.TNR, M.TNR)
)
Accuracy = (R.TPR + R.TNR) / (R.TPR + R.TNR + R.FPR + R.FNR)
R.Precision = R.TPR / (R.TPR + R.FPR)
M.Precision = M.TPR / (M.TPR + M.FPR)
AVG.Precision = (R.Precision + M.Precision) / 2
R.Recall = R.TPR / (R.TPR + R.FNR)
M.Recall = M.TPR / (M.TPR + M.FNR)
AVG.Recall = (R.Recall + M.Recall) / 2
R.Specificity = R.TNR / (R.TNR + R.FPR)
M.Specificity = M.TNR / (M.TNR + M.FPR)
AVG.Specificity = (R.Specificity + M.Specificity) / 2
F1 = 2 * (AVG.Precision * AVG.Recall) / (AVG.Precision + AVG.Recall)
sprintf(
"Dla progu decyzyjnego V9 = %0.2f dokładność (accuracy) klasyfiaktora wynosi %0.2f",
c(prog),
c(Accuracy)
)
sprintf(
"Dla progu decyzyjnego V9 = %0.2f precyzja (precision) dla klasy %s wynosi %0.2f",
c(prog),
c("R", "M"),
c(R.Precision, M.Precision)
)
sprintf(
"Dla progu decyzyjnego V9 = %0.2f średnia precyzja (precision) wynosi %0.2f",
c(prog),
c(AVG.Precision)
)
sprintf(
"Dla progu decyzyjnego V9 = %0.2f czułość (recall) dla klasy %s wynosi %0.2f",
c(prog),
c("R", "M"),
c(R.Recall, M.Recall)
)
sprintf(
"Dla progu decyzyjnego V9 = %0.2f średnia czułość (recall) wynosi %0.2f",
c(prog),
c(AVG.Recall)
)
sprintf(
"Dla progu decyzyjnego V9 = %0.2f swoistość (specificity) dla klasy %s wynosi %0.2f",
c(prog),
c("R", "M"),
c(R.Specificity, M.Specificity)
)
sprintf(
"Dla progu decyzyjnego V9 = %0.2f średnia swoistość (specificity) wynosi %0.2f",
c(prog),
c(AVG.Specificity)
)
sprintf(
"Dla progu decyzyjnego V9 = %0.2f uśredniona wartość metryki F1 dla klasyfikatora wynosi %0.2f",
c(prog),
c(F1)
)

library(openintro)
data(birds)
data = birds[,-4]
decision = mtcars$hp
summary(data)
nvmax = dim(data)[2] #ile jest deskryptorów w tym zbiorze, minus jeden decyzyjny
manyModels=regsubsets(x = decision~., data = data, nvmax = nvmax) #wyliczane dla wszystkich cech, np. nvmax = 19
library(openintro)
data(birds)
data = birds[,-4]
decision = mtcars$hp
summary(data)
nvmax = dim(data)[2] #ile jest deskryptorów w tym zbiorze, minus jeden decyzyjny
manyModels=regsubsets(x = decision~., data = data, nvmax = nvmax) #wyliczane dla wszystkich cech, np. nvmax = 19
library(openintro)
?birds
data(birds)
data = birds[,-4]
decision = mtcars$hp
summary(data)
nvmax = dim(data)[2] #ile jest deskryptorów w tym zbiorze, minus jeden decyzyjny
manyModels=regsubsets(x = decision~., data = data, nvmax = nvmax) #wyliczane dla wszystkich cech, np. nvmax = 19
library(openintro)
?birds
data(birds)
data = birds[,-1]
decision = mtcars$hp
summary(data)
nvmax = dim(data)[2] #ile jest deskryptorów w tym zbiorze, minus jeden decyzyjny
manyModels=regsubsets(x = decision~., data = data, nvmax = nvmax) #wyliczane dla wszystkich cech, np. nvmax = 19
library(openintro)
?birds
data(birds)
data = birds[,-1]
decision = mtcars$hp
summary(data)
nvmax = dim(data)[2] #ile jest deskryptorów w tym zbiorze, minus jeden decyzyjny
manyModels=regsubsets(x = decision~., data = data, nvmax = nvmax) #wyliczane dla wszystkich cech, np. nvmax = 19
library(openintro)
?birds
data(birds)
data = birds[,-1]
decision = mtcars$hp
summary(data)
nvmax = dim(data)[2] #ile jest deskryptorów w tym zbiorze, minus jeden decyzyjny
manyModels=regsubsets(x = decision~., data = data, nvmax = nvmax) #wyliczane dla wszystkich cech, np. nvmax = 19
library(openintro)
?birds
data(birds)
data = birds[,-1]
data = data[,-1]
decision = mtcars$hp
summary(data)
nvmax = dim(data)[2] #ile jest deskryptorów w tym zbiorze, minus jeden decyzyjny
manyModels=regsubsets(x = decision~., data = data, nvmax = nvmax) #wyliczane dla wszystkich cech, np. nvmax = 19
library(openintro)
?birds
data(birds)
data = birds[,-1]
data = data[,-1]
data = data[,-1]
decision = mtcars$hp
summary(data)
nvmax = dim(data)[2] #ile jest deskryptorów w tym zbiorze, minus jeden decyzyjny
manyModels=regsubsets(x = decision~., data = data, nvmax = nvmax) #wyliczane dla wszystkich cech, np. nvmax = 19
library(openintro)
?bdims
data(bdims)
data = birds[,-1]
data = data[,-1]
data = data[,-1]
decision = mtcars$hp
summary(data)
nvmax = dim(data)[2] #ile jest deskryptorów w tym zbiorze, minus jeden decyzyjny
manyModels=regsubsets(x = decision~., data = data, nvmax = nvmax) #wyliczane dla wszystkich cech, np. nvmax = 19
library(openintro)
?bdims
data(bdims)
data = bdim[,-1]
library(openintro)
?bdims
data(bdims)
data = bdims[,-1]
data = data[,-1]
data = data[,-1]
decision = mtcars$hp
summary(data)
nvmax = dim(data)[2] #ile jest deskryptorów w tym zbiorze, minus jeden decyzyjny
manyModels=regsubsets(x = decision~., data = data, nvmax = nvmax) #wyliczane dla wszystkich cech, np. nvmax = 19
library(openintro)
?bdims
data(bdims)
data = bdims[,-1]
decision = mtcars$hp
summary(data)
nvmax = dim(data)[2] #ile jest deskryptorów w tym zbiorze, minus jeden decyzyjny
manyModels=regsubsets(x = decision~., data = data, nvmax = nvmax) #wyliczane dla wszystkich cech, np. nvmax = 19
library(openintro)
?bdims
data(bdims)
data = bdims
decision = mtcars$hp
summary(data)
nvmax = dim(data)[2] #ile jest deskryptorów w tym zbiorze, minus jeden decyzyjny
manyModels=regsubsets(x = decision~., data = data, nvmax = nvmax) #wyliczane dla wszystkich cech, np. nvmax = 19
library(openintro)
?bdims
data(bdims)
data = bdims
decision = mtcars$hp
summary(data)
nvmax = dim(data)[2] #ile jest deskryptorów w tym zbiorze, minus jeden decyzyjny
manyModels=regsubsets(x = decision~., data = data, nvmax = nvmax) #wyliczane dla wszystkich cech, np. nvmax = 19
library(openintro)
?evals
data(evals)
data = evals
decision = evals$hp
summary(data)
nvmax = dim(data)[2] #ile jest deskryptorów w tym zbiorze, minus jeden decyzyjny
manyModels=regsubsets(x = decision~., data = data, nvmax = nvmax) #wyliczane dla wszystkich cech, np. nvmax = 19
library(openintro)
?evals
data(evals)
data = evals
decision = evals$score
summary(data)
nvmax = dim(data)[2] #ile jest deskryptorów w tym zbiorze, minus jeden decyzyjny
manyModels=regsubsets(x = decision~., data = data, nvmax = nvmax) #wyliczane dla wszystkich cech, np. nvmax = 19
results = summary(manyModels) #kolejne wiersze pokazują, które z deskryptorów znalazły się w modelach kolejno o 1, 2 itd. cechach.
results
print("Wartości R^2 dla kolejnych modeli:")
results$rsq #R squared, wartości dla kolejnych 1-19 modeli
#zabserwować powyżej którego nie rośnie R^2. Można wykreślić plot()
print("Wartości Adjusted R^2 dla kolejnych modeli:")
results$adjr2 #adjusted R^2, wartości dla kolejnych 19 modeli.
#zaobserwować dla którego modelu jest największe. Można wykreślić plot()
plot(manyModels, scale ="r2") #graficzne podsumowanie wszystkich modeli. Na osi pionowej ułożone rosnąco po R^2, na osi poziomej obecność lub brak danej cechy w modelu. Kolor powiązany jest z wartością na osi pionowej (nieliniowa skala - ranking wartości)
plot(manyModels, scale ="adjr2")
#max(results$adjr2)
thebestmodel = which.max(results$adjr2)
coef(manyModels, thebestmodel)
library(openintro)
?evals
data(evals)
data = evals[,-3]
decision = evals$score
summary(data)
nvmax = dim(data)[2] #ile jest deskryptorów w tym zbiorze, minus jeden decyzyjny
manyModels=regsubsets(x = decision~., data = data, nvmax = nvmax) #wyliczane dla wszystkich cech, np. nvmax = 19
results = summary(manyModels) #kolejne wiersze pokazują, które z deskryptorów znalazły się w modelach kolejno o 1, 2 itd. cechach.
results
print("Wartości R^2 dla kolejnych modeli:")
results$rsq #R squared, wartości dla kolejnych 1-19 modeli
#zabserwować powyżej którego nie rośnie R^2. Można wykreślić plot()
print("Wartości Adjusted R^2 dla kolejnych modeli:")
results$adjr2 #adjusted R^2, wartości dla kolejnych 19 modeli.
#zaobserwować dla którego modelu jest największe. Można wykreślić plot()
plot(manyModels, scale ="r2") #graficzne podsumowanie wszystkich modeli. Na osi pionowej ułożone rosnąco po R^2, na osi poziomej obecność lub brak danej cechy w modelu. Kolor powiązany jest z wartością na osi pionowej (nieliniowa skala - ranking wartości)
plot(manyModels, scale ="adjr2")
#max(results$adjr2)
thebestmodel = which.max(results$adjr2)
coef(manyModels, thebestmodel)
library(ISLR)
data(Auto)
summary(Auto)
train.size = 0.8
n = 100
descriptor = Auto$weight
decision = Auto$acceleration
hist(descriptor, xlab="vehicle weight")
hist(decision, xlab="acceleration")
A0 = array(dim = n) #wektory na współczynniki modelu
A1 = array(dim = n)
decision.modelerror = array(dim = n)
for (i in seq(n)) {
train.idx = sample(dim(Auto)[1], dim(Auto)[1] * train.size)
decision.model1 = glm(formula = decision ~ descriptor, subset = train.idx)
#zapisanie współczynników
A0[i] = coef(decision.model1)[1]
A1[i] = coef(decision.model1)[2]
decision.modelerror[i] = mean((decision[-train.idx] - (A0[i] + A1[i] * descriptor[-train.idx])) ^ 2)
}
plot(y = decision, x = descriptor, col = "gray", xlab="vehicle weight", ylab="acceleration")
for (i in seq(n)) {
points(
x = c(0, max(descriptor)),
y = c(A0[i], (max(descriptor) * A1[i] + A0[i])),
col = "green",
type = "l"
)
}
A0.mean = mean(A0)
A1.mean = mean(A1)
points(
x = c(0, max(descriptor)),
y = c(A0.mean, (max(descriptor) * A1.mean + A0.mean)),
col = "red",
type = "l"
)
decision.mean.modelerror = mean((decision - (A0.mean + A1.mean * descriptor)) ^ 2)
decision.mean.modelerror
plot(decision.modelerror, col = "purple", ylab = "Błędy modeli")
points(
x = c(0, n),
y = rep(decision.mean.modelerror, 2),
type = "l",
col = "blue"
)
n.worse = sum(decision.modelerror > decision.mean.modelerror)
sprintf("model średni lepszy od %d modeli z %d", n.worse, n)
data(Auto)
idx=sample(dim(Auto)[1])
n1 = length(idx)
hist(Auto$horsepower)
hist(Auto$mpg)
descriptor = Auto$horsepower
decision = Auto$mpg
A0_1 = array(dim = n1) #wektory na współczynniki modelu
A1_1 = array(dim = n1) #j.w.
decision.model1error = array(dim = n1) #oraz na błędy
for (i in seq(n1)) {
#wyznaczenie modelu
decision.model1 = glm(formula = decision[-i] ~ descriptor[-i])
#zapisanie współczynników
A0_1[i] = coef(decision.model1)[1]
A1_1[i] = coef(decision.model1)[2]
decision.model1error[i] = mean((decision[i] - (A0_1[i] + A1_1[i] * descriptor[i])) ^ 2)
## zastosowanie modelu:
#decision.predicted = predict(object = decision.model1, data.frame(descriptor))
## lub:
#decision.predicted = A0[i] + A1[i] * descriptor
}
k = 10
hist(Auto$horsepower)
hist(Auto$mpg)
descriptor = Auto$horsepower
decision = Auto$mpg
A0_2 = array(dim = k) #wektory na współczynniki modelu
A1_2 = array(dim = k) #j.w.
decision.model2error = array(dim = k) #oraz na błędy
for (i in seq(k)) {
fold=idx[((i-1) * floor(dim(Auto)[1]/k)+1):(i * floor(dim(Auto)[1]/k))]
#wyznaczenie modelu
decision.model2 = glm(formula = decision[-fold] ~ descriptor[-fold])
#zapisanie współczynników
A0_2[i] = coef(decision.model2)[1]
A1_2[i] = coef(decision.model2)[2]
decision.model2error[i] = mean((decision[fold] - (A0_2[i] + A1_2[i] * descriptor[fold])) ^ 2)
## zastosowanie modelu:
#decision.predicted = predict(object = decision.model1, data.frame(descriptor))
## lub:
#decision.predicted = A0[i] + A1[i] * descriptor
}
plot(y = decision, x = descriptor, col = "gray")
for (i in seq(n1)) {
points(
x = c(0, n1),
y = c(A0_1[i], (n1 * A1_1[i] + A0_1[i])),
col = "green",
type = "l"
)
}
A0_1.mean = mean(A0_1)
A1_1.mean = mean(A1_1)
points(
x = c(0, n1),
y = c(A0_1.mean, (n1 * A1_1.mean + A0_1.mean)),
col = "red",
type = "l"
)
# Wypisanie błędu
decision.mean.model1error = mean((decision - (A0_1.mean + A1_1.mean * descriptor)) ^ 2)
decision.mean.model1error
plot(decision.model1error, col = "purple", ylab = "Błędy modeli")
points(
x = c(0, n1),
y = rep(decision.mean.model1error, 2),
type = "l",
col = "blue"
)
n1.worse = sum(decision.model1error > decision.mean.model1error)
sprintf("model średni lepszy od %d modeli z %d", n1.worse, n1)
plot(y = decision, x = descriptor, col = "gray")
for (i in seq(n1)) {
points(
x = c(0, n1),
y = c(A0_2[i], (n1 * A1_2[i] + A0_2[i])),
col = "green",
type = "l"
)
}
A0_2.mean = mean(A0_2)
A1_2.mean = mean(A1_2)
points(
x = c(0, n1),
y = c(A0_2.mean, (n1 * A1_2.mean + A0_2.mean)),
col = "red",
type = "l"
)
# Wypisanie błędu
decision.mean.model2error = mean((decision - (A0_2.mean + A1_2.mean * descriptor)) ^ 2)
decision.mean.model2error
plot(decision.model2error, col = "purple", ylab = "Błędy modeli")
points(
x = c(0, n1),
y = rep(decision.mean.model2error, 2),
type = "l",
col = "blue"
)
n1.worse = sum(decision.model2error > decision.mean.model2error)
sprintf("model średni lepszy od %d modeli z %d", n1.worse, k)
library(boot)
decision.model1 = glm(mpg ~ horsepower, data = Auto)
# leave one out
cv.err = cv.glm(Auto, decision.model1)
cv.err$delta[1]
# k-fold cross-validation
k = 10
cv.error.10 = cv.glm(Auto, decision.model1, K = k)
cv.error.10$delta[1]
#install.packages('leaps')
library(leaps) #w tej bibliotece jest zestaw narzędzi: subset selection
#data = Hitters[,-19]
## lub inny zbiór danych
data = Auto[,-c(1,9)] #usuwana 9 cecha/kolumna z tabeli - nazwa modelu Auto
#decision = Hitters$Salary
#lub inny zbiór danych
decision = Auto$mpg
manyModels=regsubsets(x = decision~., data = data) #subsets dla regresji, wyznaczane na zasadzie oceny RSS wszystkich modeli o jednym deskryptorze, następnie dodaniu drugiego deskryptora, oceny RSS, itd. (patrz wykład)
#wyliczone jest do 8 pierwszych najlepszych modeli
results = summary(manyModels) #kolejne wiersze pokazują, które z deskryptorów znalazły się w modelach kolejno o 1, 2 itd. cechach.
results
data = Hitters[,-19]
decision = Hitters$Salary
nvmax = dim(data)[2] #ile jest deskryptorów w tym zbiorze, minus jeden decyzyjny
manyModels=regsubsets(x = decision~., data = data, nvmax = nvmax) #wyliczane dla wszystkich cech, np. nvmax = 19
results = summary(manyModels) #kolejne wiersze pokazują, które z deskryptorów znalazły się w modelach kolejno o 1, 2 itd. cechach.
results
print("Wartości R^2 dla kolejnych modeli:")
results$rsq #R squared, wartości dla kolejnych 1-19 modeli
#zabserwować powyżej którego nie rośnie R^2. Można wykreślić plot()
print("Wartości Adjusted R^2 dla kolejnych modeli:")
results$adjr2 #adjusted R^2, wartości dla kolejnych 19 modeli.
#zaobserwować dla którego modelu jest największe. Można wykreślić plot()
plot(manyModels, scale ="r2") #graficzne podsumowanie wszystkich modeli. Na osi pionowej ułożone rosnąco po R^2, na osi poziomej obecność lub brak danej cechy w modelu. Kolor powiązany jest z wartością na osi pionowej (nieliniowa skala - ranking wartości)
plot(manyModels, scale ="adjr2")
#max(results$adjr2)
thebestmodel = which.max(results$adjr2)
coef(manyModels, thebestmodel)
library(openintro)
?evals
data(evals)
data = evals[,-3]
decision = evals$score
#summary(data)
nvmax = dim(data)[2] #ile jest deskryptorów w tym zbiorze, minus jeden decyzyjny
manyModels=regsubsets(x = decision~., data = data, nvmax = nvmax) #wyliczane dla wszystkich cech, np. nvmax = 19
results = summary(manyModels) #kolejne wiersze pokazują, które z deskryptorów znalazły się w modelach kolejno o 1, 2 itd. cechach.
results
print("Wartości R^2 dla kolejnych modeli:")
results$rsq #R squared, wartości dla kolejnych 1-19 modeli
#zabserwować powyżej którego nie rośnie R^2. Można wykreślić plot()
print("Wartości Adjusted R^2 dla kolejnych modeli:")
results$adjr2 #adjusted R^2, wartości dla kolejnych 19 modeli.
#zaobserwować dla którego modelu jest największe. Można wykreślić plot()
plot(manyModels, scale ="r2") #graficzne podsumowanie wszystkich modeli. Na osi pionowej ułożone rosnąco po R^2, na osi poziomej obecność lub brak danej cechy w modelu. Kolor powiązany jest z wartością na osi pionowej (nieliniowa skala - ranking wartości)
plot(manyModels, scale ="adjr2")
#max(results$adjr2)
thebestmodel = which.max(results$adjr2)
coef(manyModels, thebestmodel)
library(openintro)
?fastfood
data(fastfood)
data = fastfood[,-3]
decision = fastfood$score
#summary(data)
nvmax = dim(data)[2] #ile jest deskryptorów w tym zbiorze, minus jeden decyzyjny
manyModels=regsubsets(x = decision~., data = data, nvmax = nvmax) #wyliczane dla wszystkich cech, np. nvmax = 19
library(openintro)
?fastfood
data(fastfood)
data = fastfood[,-3]
decision = fastfood$calories
#summary(data)
nvmax = dim(data)[2] #ile jest deskryptorów w tym zbiorze, minus jeden decyzyjny
manyModels=regsubsets(x = decision~., data = data, nvmax = nvmax) #wyliczane dla wszystkich cech, np. nvmax = 19
library(openintro)
?fastfood
data(fastfood)
data = fastfood[,-3]
decision = fastfood$calories
#summary(data)
nvmax = dim(data)[2] #ile jest deskryptorów w tym zbiorze, minus jeden decyzyjny
manyModels=regsubsets(x = decision~., data = data, nvmax = nvmax) #wyliczane dla wszystkich cech, np. nvmax = 19
library(openintro)
?fastfood
data(fastfood)
data = fastfood[,-3]
decision = fastfood$calories
#summary(data)
nvmax = dim(data)[2] #ile jest deskryptorów w tym zbiorze, minus jeden decyzyjny
manyModels=regsubsets(x = decision~., data = data, nvmax = nvmax) #wyliczane dla wszystkich cech, np. nvmax = 19
library(openintro)
?fastfood
data(fastfood)
data = fastfood[,-3]
decision = fastfood$calories
summary(data)
nvmax = dim(data)[2] #ile jest deskryptorów w tym zbiorze, minus jeden decyzyjny
manyModels=regsubsets(x = decision~., data = data, nvmax = nvmax) #wyliczane dla wszystkich cech, np. nvmax = 19
library(openintro)
?fastfood
data(fastfood)
data = fastfood[,-3]
decision = fastfood$calories
summary(data)
nvmax = dim(data)[2] #ile jest deskryptorów w tym zbiorze, minus jeden decyzyjny
manyModels=regsubsets(x = decision~., data = data, nvmax = nvmax) #wyliczane dla wszystkich cech, np. nvmax = 19
library(openintro)
?gifted
data(gifted)
data = gifted[,-3]
decision = gifted$calories
summary(data)
nvmax = dim(data)[2] #ile jest deskryptorów w tym zbiorze, minus jeden decyzyjny
manyModels=regsubsets(x = decision~., data = data, nvmax = nvmax) #wyliczane dla wszystkich cech, np. nvmax = 19
library(openintro)
?gifted
data(gifted)
data = gifted[,-1]
decision = gifted$score
summary(data)
nvmax = dim(data)[2] #ile jest deskryptorów w tym zbiorze, minus jeden decyzyjny
manyModels=regsubsets(x = decision~., data = data, nvmax = nvmax) #wyliczane dla wszystkich cech, np. nvmax = 19
results = summary(manyModels) #kolejne wiersze pokazują, które z deskryptorów znalazły się w modelach kolejno o 1, 2 itd. cechach.
results
print("Wartości R^2 dla kolejnych modeli:")
results$rsq #R squared, wartości dla kolejnych 1-19 modeli
#zabserwować powyżej którego nie rośnie R^2. Można wykreślić plot()
print("Wartości Adjusted R^2 dla kolejnych modeli:")
results$adjr2 #adjusted R^2, wartości dla kolejnych 19 modeli.
#zaobserwować dla którego modelu jest największe. Można wykreślić plot()
plot(manyModels, scale ="r2") #graficzne podsumowanie wszystkich modeli. Na osi pionowej ułożone rosnąco po R^2, na osi poziomej obecność lub brak danej cechy w modelu. Kolor powiązany jest z wartością na osi pionowej (nieliniowa skala - ranking wartości)
plot(manyModels, scale ="adjr2")
#max(results$adjr2)
thebestmodel = which.max(results$adjr2)
coef(manyModels, thebestmodel)
library(openintro)
?gifted
data(gifted)
data = gifted[,-1]
decision = gifted$score
summary(data)
nvmax = dim(data)[2]
manyModels=regsubsets(x = decision~., data = data, nvmax = nvmax)
library(openintro)
?gifted
data(gifted)
data = gifted[,-1]
decision = gifted$score
summary(data)
nvmax = dim(data)[2]
manyModels=regsubsets(x = decision~., data = data, nvmax = nvmax)
library(openintro)
?gifted
data(gifted)
data = gifted[,-1]
decision = gifted$score
summary(data)
nvmax = dim(data)[2]
manyModels=regsubsets(x = decision~., data = data, nvmax = nvmax)
library(leaps)
library(openintro)
?gifted
data(gifted)
data = gifted[,-1]
decision = gifted$score
summary(data)
nvmax = dim(data)[2]
manyModels=regsubsets(x = decision~., data = data, nvmax = nvmax)
results = summary(manyModels)
results
print("Wartości R^2 dla kolejnych modeli:")
results$rsq
#zabserwować powyżej którego nie rośnie R^2. Można wykreślić plot()
print("Wartości Adjusted R^2 dla kolejnych modeli:")
results$adjr2
#zaobserwować dla którego modelu jest największe. Można wykreślić plot()
plot(manyModels, scale ="r2")
plot(manyModels, scale ="adjr2")
#max(results$adjr2)
thebestmodel = which.max(results$adjr2)
coef(manyModels, thebestmodel)
library(leaps)
library(openintro)
?gifted
data(gifted)
data = gifted[,-1]
decision = gifted$score
summary(data)
nvmax = dim(data)[2]
manyModels=regsubsets(x = decision~., data = data, nvmax = nvmax)
results = summary(manyModels)
results
print("Wartości RSS dla kolejnych modeli:")
results$rsq
#zabserwować powyżej którego nie rośnie R^2. Można wykreślić plot()
print("Wartości Adjusted RSS dla kolejnych modeli:")
results$adjr2
#zaobserwować dla którego modelu jest największe. Można wykreślić plot()
plot(manyModels, scale ="RSS")

train.size = 0.8
train.idx = sample(dim(iris)[1], dim(iris)[1] * train.size)
train = iris[train.idx,]
test = iris[-train.idx,]
print(train)
print(test)
tree<- tree(Species~., data = iris, subset = train.idx)
wyniki.cv = cv.tree(tree, FUN = prune.misclass)
sprintf("kolejne drzewa miały liczbę liści:")
sprintf("%d",wyniki.cv$size)
sprintf("kolejne drzewa miały błąd kros walidacji:")
sprintf("%d",wyniki.cv$dev)
sprintf("najmniejsze drzewo o najmniejszym błędzie to drzewo o 3 liściach")
print(tree)
wyniki_pełne_train = predict(tree, newdata = train, type = "class")
table(wyniki_pełne_train, iris$Species[train.idx])
wyniki_pełne_test = predict(tree, newdata = test, type = "class")
table(wyniki_pełne_test, iris$Species[-train.idx])
# drzewo przycięte
tree.pruned=prune.misclass(tree, best = 3)
plot(tree.pruned)
text(tree.pruned, pretty = 0)
wyniki_prunned_train = predict(tree.pruned, newdata = train, type = "class")
table(wyniki_pełne_train, iris$Species[train.idx])
wyniki_prunned_test = predict(tree.pruned, newdata = test, type = "class")
table(wyniki_pełne_test, iris$Species[-train.idx])
library(tree)
set.seed(6)
data(iris)
train.size = 0.8
train.idx = sample(dim(iris)[1], dim(iris)[1] * train.size)
train = iris[train.idx,]
test = iris[-train.idx,]
print(train)
print(test)
tree<- tree(Species~., data = iris, subset = train.idx)
wyniki.cv = cv.tree(tree, FUN = prune.misclass)
sprintf("kolejne drzewa miały liczbę liści:")
sprintf("%d",wyniki.cv$size)
sprintf("kolejne drzewa miały błąd kros walidacji:")
sprintf("%d",wyniki.cv$dev)
sprintf("najmniejsze drzewo o najmniejszym błędzie to drzewo o 3 liściach")
print(tree)
wyniki_pełne_train = predict(tree, newdata = train, type = "class")
table(wyniki_pełne_train, iris$Species[train.idx])
wyniki_pełne_test = predict(tree, newdata = test, type = "class")
table(wyniki_pełne_test, iris$Species[-train.idx])
# drzewo przycięte
tree.pruned=prune.misclass(tree, best = 3)
plot(tree.pruned)
text(tree.pruned, pretty = 0)
wyniki_prunned_train = predict(tree.pruned, newdata = train, type = "class")
table(wyniki_prunned_train, iris$Species[train.idx])
wyniki_prunned_test = predict(tree.pruned, newdata = test, type = "class")
table(wyniki_prunned_test, iris$Species[-train.idx])
library(tree)
set.seed(6)
data(iris)
train.size = 0.8
train.idx = sample(dim(iris)[1], dim(iris)[1] * train.size)
train = iris[train.idx,]
test = iris[-train.idx,]
print(train)
print(test)
tree<- tree(Species~., data = iris, subset = train.idx)
wyniki.cv = cv.tree(tree, FUN = prune.misclass)
sprintf("kolejne drzewa miały liczbę liści:")
sprintf("%d",wyniki.cv$size)
sprintf("kolejne drzewa miały błąd kros walidacji:")
sprintf("%d",wyniki.cv$dev)
sprintf("najmniejsze drzewo o najmniejszym błędzie to drzewo o 3 liściach")
print(tree)
wyniki_pełne_train = predict(tree, newdata = train, type = "class")
table(wyniki_pełne_train, iris$Species[train.idx])
wyniki_pełne_test = predict(tree, newdata = test, type = "class")
table(wyniki_pełne_test, iris$Species[-train.idx])
# drzewo przycięte
tree.pruned=prune.misclass(tree, best = 3)
plot(tree.pruned)
text(tree.pruned, pretty = 0)
wyniki_prunned_train = predict(tree.pruned, newdata = train, type = "class")
table(wyniki_prunned_train, iris$Species[train.idx])
wyniki_prunned_test = predict(tree.pruned, newdata = test, type = "class")
table(wyniki_prunned_test, iris$Species[-train.idx])
library(tree)
set.seed(6)
data(iris)
train.size = 0.8
train.idx = sample(dim(iris)[1], dim(iris)[1] * train.size)
train = iris[train.idx,]
test = iris[-train.idx,]
print(train)
print(test)
tree<- tree(Species~., data = iris, subset = train.idx)
wyniki.cv = cv.tree(tree, FUN = prune.misclass)
sprintf("kolejne drzewa miały liczbę liści:")
sprintf("%d",wyniki.cv$size)
sprintf("kolejne drzewa miały błąd kros walidacji:")
sprintf("%d",wyniki.cv$dev)
sprintf("najmniejsze drzewo o najmniejszym błędzie to drzewo o 3 liściach")
prot(tree)
library(tree)
set.seed(6)
data(iris)
train.size = 0.8
train.idx = sample(dim(iris)[1], dim(iris)[1] * train.size)
train = iris[train.idx,]
test = iris[-train.idx,]
print(train)
print(test)
tree<- tree(Species~., data = iris, subset = train.idx)
wyniki.cv = cv.tree(tree, FUN = prune.misclass)
sprintf("kolejne drzewa miały liczbę liści:")
sprintf("%d",wyniki.cv$size)
sprintf("kolejne drzewa miały błąd kros walidacji:")
sprintf("%d",wyniki.cv$dev)
sprintf("najmniejsze drzewo o najmniejszym błędzie to drzewo o 3 liściach")
plot(tree)
wyniki_pełne_train = predict(tree, newdata = train, type = "class")
table(wyniki_pełne_train, iris$Species[train.idx])
wyniki_pełne_test = predict(tree, newdata = test, type = "class")
table(wyniki_pełne_test, iris$Species[-train.idx])
# drzewo przycięte
tree.pruned=prune.misclass(tree, best = 3)
plot(tree.pruned)
text(tree.pruned, pretty = 0)
wyniki_prunned_train = predict(tree.pruned, newdata = train, type = "class")
table(wyniki_prunned_train, iris$Species[train.idx])
wyniki_prunned_test = predict(tree.pruned, newdata = test, type = "class")
table(wyniki_prunned_test, iris$Species[-train.idx])
library(tree)
set.seed(6)
data(iris)
train.size = 0.8
train.idx = sample(dim(iris)[1], dim(iris)[1] * train.size)
train = iris[train.idx,]
test = iris[-train.idx,]
print(train)
print(test)
tree<- tree(Species~., data = iris, subset = train.idx)
wyniki.cv = cv.tree(tree, FUN = prune.misclass)
sprintf("kolejne drzewa miały liczbę liści:")
sprintf("%d",wyniki.cv$size)
sprintf("kolejne drzewa miały błąd kros walidacji:")
sprintf("%d",wyniki.cv$dev)
sprintf("najmniejsze drzewo o najmniejszym błędzie to drzewo o 3 liściach")
plot(tree)
wyniki_pełne_train = predict(tree, newdata = train, type = "class")
table(wyniki_pełne_train, iris$Species[train.idx])
wyniki_pełne_test = predict(tree, newdata = test, type = "class")
table(wyniki_pełne_test, iris$Species[-train.idx])
# drzewo przycięte
tree.pruned=prune.misclass(tree, best = 3)
plot(tree.pruned)
text(tree.pruned, pretty = 0)
wyniki_prunned_train = predict(tree.pruned, newdata = train, type = "class")
table(wyniki_prunned_train, iris$Species[train.idx])
wyniki_prunned_test = predict(tree.pruned, newdata = test, type = "class")
table(wyniki_prunned_test, iris$Species[-train.idx])
library(tree)
set.seed(6)
data(iris)
train.size = 0.8
train.idx = sample(dim(iris)[1], dim(iris)[1] * train.size)
train = iris[train.idx,]
test = iris[-train.idx,]
print(train)
print(test)
tree<- tree(Species~., data = iris, subset = train.idx)
wyniki.cv = cv.tree(tree, FUN = prune.misclass)
sprintf("kolejne drzewa miały liczbę liści:")
sprintf("%d",wyniki.cv$size)
sprintf("kolejne drzewa miały błąd kros walidacji:")
sprintf("%d",wyniki.cv$dev)
sprintf("najmniejsze drzewo o najmniejszym błędzie to drzewo o 3 liściach")
plot(tree)
text(tree, pretty = 0)
wyniki_pełne_train = predict(tree, newdata = train, type = "class")
table(wyniki_pełne_train, iris$Species[train.idx])
wyniki_pełne_test = predict(tree, newdata = test, type = "class")
table(wyniki_pełne_test, iris$Species[-train.idx])
# drzewo przycięte
tree.pruned=prune.misclass(tree, best = 3)
plot(tree.pruned)
text(tree.pruned, pretty = 0)
wyniki_prunned_train = predict(tree.pruned, newdata = train, type = "class")
table(wyniki_prunned_train, iris$Species[train.idx])
wyniki_prunned_test = predict(tree.pruned, newdata = test, type = "class")
table(wyniki_prunned_test, iris$Species[-train.idx])
library(tree)
set.seed(6)
data(iris)
train.size = 0.8
train.idx = sample(dim(iris)[1], dim(iris)[1] * train.size)
train = iris[train.idx,]
test = iris[-train.idx,]
print(train)
print(test)
tree<- tree(Species~., data = iris, subset = train.idx)
wyniki.cv = cv.tree(tree, FUN = prune.misclass)
sprintf("kolejne drzewa miały liczbę liści:")
sprintf("%d",wyniki.cv$size)
sprintf("kolejne drzewa miały błąd kros walidacji:")
sprintf("%d",wyniki.cv$dev)
sprintf("najmniejsze drzewo o najmniejszym błędzie to drzewo o 3 liściach")
plot(tree)
text(tree, pretty = 0)
wyniki_pełne_train = predict(tree, newdata = train, type = "class")
table(wyniki_pełne_train, iris$Species[train.idx])
wyniki_pełne_test = predict(tree, newdata = test, type = "class")
table(wyniki_pełne_test, iris$Species[-train.idx])
# drzewo przycięte
tree.pruned=prune.misclass(tree, best = 3)
plot(tree.pruned)
text(tree.pruned, pretty = 0)
wyniki_prunned_train = predict(tree.pruned, newdata = train, type = "class")
table(wyniki_prunned_train, iris$Species[train.idx])
wyniki_prunned_test = predict(tree.pruned, newdata = test, type = "class")
table(wyniki_prunned_test, iris$Species[-train.idx])
# drzewo mocno przycięte
tree.pruned=prune.misclass(tree, best = 2)
plot(tree.pruned)
text(tree.pruned, pretty = 0)
wyniki_prunned_train = predict(tree.pruned, newdata = train, type = "class")
table(wyniki_prunned_train, iris$Species[train.idx])
wyniki_prunned_test = predict(tree.pruned, newdata = test, type = "class")
table(wyniki_prunned_test, iris$Species[-train.idx])
library(tree)
set.seed(6)
data(iris)
train.size = 0.8
train.idx = sample(dim(iris)[1], dim(iris)[1] * train.size)
train = iris[train.idx,]
test = iris[-train.idx,]
print(train)
print(test)
tree<- tree(Species~., data = iris, subset = train.idx)
wyniki.cv = cv.tree(tree, FUN = prune.misclass)
sprintf("kolejne drzewa miały liczbę liści:")
sprintf("%d",wyniki.cv$size)
sprintf("kolejne drzewa miały błąd kros walidacji:")
sprintf("%d",wyniki.cv$dev)
sprintf("najmniejsze drzewo o najmniejszym błędzie to drzewo o 3 liściach")
plot(tree)
text(tree, pretty = 0)
wyniki_pełne_train = predict(tree, newdata = train, type = "class")
table(wyniki_pełne_train, iris$Species[train.idx])
wyniki_pełne_test = predict(tree, newdata = test, type = "class")
table(wyniki_pełne_test, iris$Species[-train.idx])
# drzewo przycięte
tree.pruned=prune.misclass(tree, best = 3)
plot(tree.pruned)
text(tree.pruned, pretty = 0)
wyniki_prunned_train = predict(tree.pruned, newdata = train, type = "class")
table(wyniki_prunned_train, iris$Species[train.idx])
wyniki_prunned_test = predict(tree.pruned, newdata = test, type = "class")
table(wyniki_prunned_test, iris$Species[-train.idx])
# drzewo mocno przycięte
tree.pruned_hard=prune.misclass(tree, best = 2)
plot(tree.pruned_hard)
text(tree.pruned_hard, pretty = 0)
wyniki_pruned_hard_train = predict(tree.pruned_hard, newdata = train, type = "class")
table(wyniki_pruned_hard_train, iris$Species[train.idx])
wyniki_pruned_hard_test = predict(tree.pruned_hard, newdata = test, type = "class")
table(wyniki_pruned_hard_test, iris$Species[-train.idx])
library(tree)
set.seed(6)
data(iris)
train.size = 0.8
train.idx = sample(dim(iris)[1], dim(iris)[1] * train.size)
train = iris[train.idx,]
test = iris[-train.idx,]
print(train)
print(test)
tree<- tree(Species~., data = iris, subset = train.idx)
wyniki.cv = cv.tree(tree, FUN = prune.misclass)
sprintf("kolejne drzewa miały liczbę liści:")
sprintf("%d",wyniki.cv$size)
sprintf("kolejne drzewa miały błąd kros walidacji:")
sprintf("%d",wyniki.cv$dev)
sprintf("najmniejsze drzewo o najmniejszym błędzie to drzewo o 3 liściach")
plot(tree)
text(tree, pretty = 0)
wyniki_pełne_train = predict(tree, newdata = train, type = "class")
table(wyniki_pełne_train, iris$Species[train.idx])
wyniki_pełne_test = predict(tree, newdata = test, type = "class")
table(wyniki_pełne_test, iris$Species[-train.idx])
# drzewo przycięte
tree.pruned=prune.misclass(tree, best = 3)
plot(tree.pruned)
text(tree.pruned, pretty = 0)
wyniki_prunned_train = predict(tree.pruned, newdata = train, type = "class")
table(wyniki_prunned_train, iris$Species[train.idx])
wyniki_prunned_test = predict(tree.pruned, newdata = test, type = "class")
table(wyniki_prunned_test, iris$Species[-train.idx])
# drzewo mocno przycięte
tree.pruned_hard=prune.misclass(tree, best = 2)
plot(tree.pruned_hard)
text(tree.pruned_hard, pretty = 0)
wyniki_pruned_hard_train = predict(tree.pruned_hard, newdata = train, type = "class")
table(wyniki_pruned_hard_train, iris$Species[train.idx])
wyniki_pruned_hard_test = predict(tree.pruned_hard, newdata = test, type = "class")
table(wyniki_pruned_hard_test, iris$Species[-train.idx])
library(tree)
set.seed(6)
data(iris)
train.size = 0.8
train.idx = sample(dim(iris)[1], dim(iris)[1] * train.size)
train = iris[train.idx,]
test = iris[-train.idx,]
print(train)
print(test)
tree<- tree(Species~., data = iris, subset = train.idx)
wyniki.cv = cv.tree(tree, FUN = prune.misclass)
sprintf("kolejne drzewa miały liczbę liści:")
sprintf("%d",wyniki.cv$size)
sprintf("kolejne drzewa miały błąd kros walidacji:")
sprintf("%d",wyniki.cv$dev)
sprintf("najmniejsze drzewo o najmniejszym błędzie to drzewo o 3 liściach")
plot(tree)
text(tree, pretty = 0)
wyniki_pełne_train = predict(tree, newdata = train, type = "class")
table(wyniki_pełne_train, iris$Species[train.idx])
wyniki_pełne_test = predict(tree, newdata = test, type = "class")
table(wyniki_pełne_test, iris$Species[-train.idx])
# drzewo przycięte
tree.pruned=prune.misclass(tree, best = 3)
plot(tree.pruned)
text(tree.pruned, pretty = 0)
wyniki_prunned_train = predict(tree.pruned, newdata = train, type = "class")
table(wyniki_prunned_train, iris$Species[train.idx])
wyniki_prunned_test = predict(tree.pruned, newdata = test, type = "class")
table(wyniki_prunned_test, iris$Species[-train.idx])
# drzewo mocno przycięte
tree.pruned_hard=prune.misclass(tree, best = 2)
plot(tree.pruned_hard)
text(tree.pruned_hard, pretty = 0)
wyniki_pruned_hard_train = predict(tree.pruned_hard, newdata = train, type = "class")
table(wyniki_pruned_hard_train, iris$Species[train.idx])
wyniki_pruned_hard_test = predict(tree.pruned_hard, newdata = test, type = "class")
table(wyniki_pruned_hard_test, iris$Species[-train.idx])
library(ISLR)
set.seed(25)
t = median(Auto$mpg)
train.size = 0.8
d = rep("bad",dim(Auto)[1])
d[Auto$mpg<t] = "good"
data = Auto[,c(-1,-9)]
train.idx = sample(dim(Auto)[1], dim(Auto)[1] * train.size)
train = data[train.idx,]
test = data[-train.idx,]
?predict.rpart
tree <- rpart(d~., data = data, subset = train.idx, method = 'class')
library(ISLR)
library(rpart)
library(rpart.plot)
set.seed(25)
t = median(Auto$mpg)
train.size = 0.8
d = rep("bad",dim(Auto)[1])
d[Auto$mpg<t] = "good"
data = Auto[,c(-1,-9)]
train.idx = sample(dim(Auto)[1], dim(Auto)[1] * train.size)
train = data[train.idx,]
test = data[-train.idx,]
?predict.rpart
tree <- rpart(d~., data = data, subset = train.idx, method = 'class')
wyniki = predict(tree, newdata = test, type = "class")
rpart.plot(tree)
tree_pruned002 = prune.rpart(tree, cp = 0.02)
wyniki_pruned002=predict(tree_pruned002, newdata = test, type = "class")
rpart.plot(tree_pruned002)
print(train)
print(test)
liczba_good = sum(d[-train.idx] == "good")
liczba_bad = sum(d[-train.idx] == "bad")
liczba_all = length(d[-train.idx])
# drzewo pełne
good_true = sum(d[-train.idx][wyniki == "good"] == "good")
good_true_positive = good_true / liczba_good #true positive rate
bad_true = sum(d[-train.idx][wyniki == "bad"] == "bad")
bad_true_negative = bad_true / liczba_bad #true negative rate
good_false = sum(d[-train.idx][wyniki == "good"] == "bad")
good_false_positive = good_false / liczba_bad #false positive rate
bad_false = sum(d[-train.idx][wyniki == "bad"] == "good")
bad_false_negative = bad_false / liczba_good #false negative rate
writeLines("\nWyniki dla drzewa pełnego:")
table(wyniki, d[-train.idx])
sprintf(
"True positive rate wynosi %0.2f",
c(good_true_positive)
)
sprintf(
"True negative rate wynosi %0.2f",
c(bad_true_negative)
)
sprintf(
"False positive rate wynosi %0.2f",
c(good_false_positive)
)
sprintf(
"False negative rate wynosi %0.2f",
c(bad_false_negative)
)
Accuracy = (good_true + bad_true) / liczba_all
Precision = good_true / (good_true + good_false)
Recall = good_true / (good_true + bad_false)
Specificity = bad_true / (bad_true + good_false)
F1 = 2 * (Precision * Recall) / (Precision + Recall)
sprintf(
"dokładność (accuracy) klasyfiaktora wynosi %0.2f",
c(Accuracy)
)
sprintf(
"precyzja (precision) klasyfiaktora wynosi %0.2f",
c(Precision)
)
sprintf(
"czułość (recall) klasyfiaktora wynosi %0.2f",
c(Recall)
)
sprintf(
"swoistość (specificity) klasyfiaktora wynosi %0.2f",
c(Specificity)
)
sprintf(
"wskaźnik F1 dla klasyfikatora wynosi %0.2f",
c(F1)
)
# drzewo przycięte
good_true_pruned = sum(d[-train.idx][wyniki_pruned002 == "good"] == "good")
good_true_positive_pruned = good_true_pruned / liczba_good #true positive rate
bad_true_pruned = sum(d[-train.idx][wyniki_pruned002 == "bad"] == "bad")
bad_true_negative_pruned = bad_true_pruned / liczba_bad #true negative rate
good_false_pruned = sum(d[-train.idx][wyniki_pruned002 == "good"] == "bad")
good_false_positive_pruned = good_false_pruned / liczba_bad #false positive rate
bad_false_pruned = sum(d[-train.idx][wyniki_pruned002 == "bad"] == "good")
bad_false_negative_pruned = bad_false_pruned / liczba_good #false negative rate
writeLines("\nWyniki dla drzewa przyciętego:")
table(wyniki_pruned002, d[-train.idx])
sprintf(
"True positive rate wynosi %0.2f",
c(good_true_positive_pruned)
)
sprintf(
"True negative rate wynosi %0.2f",
c(bad_true_negative_pruned)
)
sprintf(
"False positive rate wynosi %0.2f",
c(good_false_positive_pruned)
)
sprintf(
"False negative rate wynosi %0.2f",
c(bad_false_negative_pruned)
)
Accuracy_pruned = (good_true_pruned + bad_true_pruned) / liczba_all
Precision_pruned = good_true_pruned / (good_true_pruned + good_false_pruned)
Recall_pruned = good_true_pruned / (good_true_pruned + bad_false_pruned)
Specificity_pruned = bad_true_pruned / (bad_true_pruned + good_false_pruned)
F1_pruned = 2 * (Precision_pruned * Recall_pruned) / (Precision_pruned + Recall_pruned)
sprintf(
"dokładność (accuracy) klasyfiaktora wynosi %0.2f",
c(Accuracy_pruned)
)
sprintf(
"precyzja (precision) klasyfiaktora wynosi %0.2f",
c(Precision_pruned)
)
sprintf(
"czułość (recall) klasyfiaktora wynosi %0.2f",
c(Recall_pruned)
)
sprintf(
"swoistość (specificity) klasyfiaktora wynosi %0.2f",
c(Specificity_pruned)
)
sprintf(
"wskaźnik F1 dla klasyfikatora wynosi %0.2f",
c(F1_pruned)
)
MSIPassed <- c("passed", "failed", "failed", "passed", "passed", "failed", "failed", "passed", "passed", "failed", "passed", "failed", "passed", "passed", "failed", "failed", "passed", "failed", "passed", "passed")
probabilities = proportions(table(MSIPassed))
MSIPassed.H=-sum(probabilities*log2(probabilities))
probabilities
sprintf("Entropia decyzji H(MSIPassed) = %.3f",MSIPassed.H)
H = function(inputs){
probabilities <- table(inputs)/length(inputs)
H=-sum(probabilities*log2(probabilities))
return(H)
}
AKOPassed <- c("passed", "failed", "failed", "failed", "passed", "failed", "failed", "passed", "passed", "failed", "passed", "failed", "passed", "passed", "failed", "failed", "failed", "failed", "failed", "passed")
AKOPassed.H = H(AKOPassed)
MSIPassed.AKOPassed = MSIPassed[AKOPassed=="passed"]
MSIPassed.AKOFailed = MSIPassed[AKOPassed=="failed"]
MSIPassed.Hcondit.AKOPassed = H(MSIPassed.AKOPassed) * proportions(table(AKOPassed))["passed"] +
H(MSIPassed.AKOFailed) * proportions(table(AKOPassed))["failed"]
H = function(inputs){
probabilities <- table(inputs)/length(inputs)
H=-sum(probabilities*log2(probabilities))
return(H)
}
AKOPassed <- c("passed", "failed", "failed", "failed", "passed", "failed", "failed", "passed", "passed", "failed", "passed", "failed", "passed", "passed", "failed", "failed", "failed", "failed", "failed", "passed")
AKOPassed.H = H(AKOPassed)
MSIPassed.AKOPassed = MSIPassed[AKOPassed=="passed"]
MSIPassed.AKOFailed = MSIPassed[AKOPassed=="failed"]
MSIPassed.Hcondit.AKOPassed = H(MSIPassed.AKOPassed) * proportions(table(AKOPassed))["passed"] +
H(MSIPassed.AKOFailed) * proportions(table(AKOPassed))["failed"]
MSIPassed.IG.AKOPassed = MSIPassed.H - MSIPassed.Hcondit.AKOPassed
sprintf("Entropia decyzji H(MSIPassed) = %.3f",MSIPassed.H)
sprintf("Entropia decyzji H(MSIPassed|AKOPassed) = %.3f",MSIPassed.Hcondit.AKOPassed)
sprintf("Zysk informacyjny IG(MSIPassed|AKOPassed) = %.3f",MSIPassed.IG.AKOPassed)
